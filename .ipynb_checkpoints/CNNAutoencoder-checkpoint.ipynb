{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, Reshape, UpSampling2D, BatchNormalization, AveragePooling2D, Activation, Lambda, Conv2DTranspose, ReLU\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l1\n",
    "\n",
    "in_height = 720//2\n",
    "in_width =  1280//2\n",
    "\n",
    "#out_height = 720\n",
    "#out_width = 1280\n",
    "\n",
    "out_height = in_height\n",
    "out_width = in_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 360, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 360, 640, 8)       224       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 360, 640, 8)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 180, 320, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 180, 320, 16)      1168      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 180, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 90, 160, 16)       2320      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 45, 80, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "=================================================================\n",
      "Total params: 3,712\n",
      "Trainable params: 3,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 45, 80, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 90, 160, 16)       2320      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 180, 320, 16)      2320      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 180, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 360, 640, 8)       1160      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 360, 640, 3)       27        \n",
      "=================================================================\n",
      "Total params: 5,827\n",
      "Trainable params: 5,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.losses import *\n",
    "encoder_input =  Input(shape=(in_height,in_width,3))\n",
    "\n",
    "# Encoder Layers\n",
    "encoder = Conv2D(8, (3, 3),padding='same', kernel_constraint=maxnorm(1.5))(encoder_input)\n",
    "encoder = Activation('relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same',)(encoder)\n",
    "encoder = Conv2D(16, (3, 3), padding='same', kernel_constraint=maxnorm(1.5))(encoder)\n",
    "encoder = Activation('relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "encoder = Conv2D(16, (3, 3), padding='same', kernel_constraint=maxnorm(1.5))(encoder)\n",
    "encoder = Activation('relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "encoder =  Flatten(name='flatten_1')(encoder)\n",
    "\n",
    "encoder_model = Model(encoder_input,encoder)\n",
    "encoder_model.summary()\n",
    "\n",
    "#encoder_model.load_weights(\"16C-360x640-encoder.h5\")\n",
    "\n",
    "# Decoder Layers\n",
    "decoder_input = Input(shape=(45 * 80 * 16,))\n",
    "decoder = Reshape(( 45, 80, 16))(decoder_input)\n",
    "decoder = Conv2DTranspose(16, (3, 3), padding='same',strides=2, kernel_constraint=maxnorm(1.5))(decoder)\n",
    "decoder = Activation('relu')(decoder)\n",
    "decoder = Conv2DTranspose(16, (3, 3), padding='same',strides=2, kernel_constraint=maxnorm(1.5))(decoder)\n",
    "decoder = Activation('relu')(decoder)\n",
    "decoder = Conv2DTranspose(8, (3, 3), padding='same',strides=2, kernel_constraint=maxnorm(1.5))(decoder)\n",
    "decoder = Conv2DTranspose(3, (1, 1), padding='same')(decoder)\n",
    "\n",
    "#decoder = ReLU(max_value=255)(decoder)\n",
    "decoder_model = Model(decoder_input,decoder)\n",
    "decoder_model.summary()\n",
    "\n",
    "autoencoder = Model(encoder_input,decoder_model(encoder))\n",
    "autoencoder.compile(optimizer='adam',  loss=logcosh,metrics=['acc'])\n",
    "\n",
    "#autoencoder.load_weights('16C-Text--Images-autoencoder-weights-model-13-360x640-360x640.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayan\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 360, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 360, 640, 8)       224       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 360, 640, 8)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_16 (Averag (None, 180, 320, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 180, 320, 16)      1168      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 180, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_17 (Averag (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 90, 160, 16)       2320      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_18 (Averag (None, 45, 80, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "model_13 (Model)             (None, 360, 640, 3)       5827      \n",
      "=================================================================\n",
      "Total params: 9,539\n",
      "Trainable params: 9,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "encoder_model = load_model(\"16C-360x640-encoder.h5\")\n",
    "decoder_model = load_model(\"16C-360x640-decoder.h5\")\n",
    "\n",
    "autoencoder = Model(encoder_model.inputs,decoder_model(encoder_model.outputs))\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer='adam',  loss=logcosh,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(autoencoder, './tensorflowjs-model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "train_dir = \"../Datasets/DIV2K_train_HR/\"\n",
    "valid_dir = \"../Datasets/DIV2K_valid_HR/\"\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "#files = pd.read_csv('image_data.csv').Path\n",
    "train_files = os.listdir(train_dir)\n",
    "valid_files = os.listdir(valid_dir)\n",
    "\n",
    "def getImage(file):\n",
    "    #â€ªC:\\Users\\mayan\\Downloads\\2-dog.jpg\n",
    "    frame = cv2.imread(file,1)\n",
    "    return [np.array([cv2.resize(frame,(in_width,in_height))]),np.array([cv2.resize(frame,(out_width,out_height))])]\n",
    "\n",
    "def getValidation():\n",
    "    x_valid,y_valid = [],[]   \n",
    "    for file in valid_files:\n",
    "        frame = cv2.imread(valid_dir + file,1)\n",
    "        try:\n",
    "            #y_valid.append(cv2.resize(frame,(out_width,out_height)))\n",
    "            x_valid.append(cv2.resize(frame,(in_width,in_height)))\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "    return np.array(x_valid),np.array(y_valid)\n",
    "\n",
    "\n",
    "for file in train_files:\n",
    "    frame = cv2.imread(train_dir + file,1)\n",
    "    try:\n",
    "        X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "x_valid,y_valid = getValidation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_output = encoder_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"images.npy\",X)\n",
    "np.save(\"encoded_output.npy\",encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'shape'\n",
      "'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(\"./../Datasets/flickr30k_images/\")\n",
    "for file in train_files:\n",
    "    frame = cv2.imread( './../Datasets/flickr30k_images/'+ file,1)\n",
    "    try:\n",
    "        height, width, channels = frame.shape\n",
    "        if height >= in_height and width >= in_width:\n",
    "            X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5874 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        'D:\\\\Fast and Furious',\n",
    "        target_size=(in_height, in_width),\n",
    "        batch_size=1,\n",
    "        class_mode=\"input\")\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "Test Loss 3.721118211746216\n",
      "Test Accuracy 0.884314239025116\n",
      "Epoch 1/10\n",
      " 413/3249 [==>...........................] - ETA: 3:32 - loss: 3.7018 - acc: 0.8671"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-91ff619a3e3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 batch_size=8,validation_data = (x_valid,x_valid))\n\u001b[0;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3249\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "\n",
    "validation_accuracy = 0.7050989866256714\n",
    "learning_rate = (1-validation_accuracy)/10000\n",
    "\n",
    "#it = datagen.flow(np.array(X),batch_size=512,shuffle = True)\n",
    "\n",
    "x_test = getImage('C:/Users/mayan/Desktop/tensorflow-autoencoder/static/pexels-photo-257840.jpeg')[0];\n",
    "\n",
    "while True:\n",
    "    \"\"\"\n",
    "    X_ = next(train_generator)[0]  \n",
    "    hist = autoencoder.fit(X_,\n",
    "                epochs=10,\n",
    "                batch_size=8,validation_data = (x_valid,x_valid))\n",
    "    \"\"\"\n",
    "    autoencoder.fit_generator(train_generator,steps_per_epoch=5874,validation_data=(x_valid,x_valid),epochs=10)\n",
    "    clear_output() \n",
    "    \n",
    "    decoded_imgs = autoencoder.predict(x_test)\n",
    "    h = autoencoder.evaluate(x_test,x_test)\n",
    "    \n",
    "    print(\"Test Loss\",h[0])\n",
    "    print(\"Test Accuracy\",h[1])\n",
    "    \n",
    "    cv2.imwrite(\"./restructured/test_image.jpg\" ,decoded_imgs[0])\n",
    "    cv2.imwrite(\"./restructured/original-test_image.jpg\" ,x_test[0])\n",
    "    \n",
    "    decoder_model.save(\"16C-%dx%d-decoder.h5\"%(out_height,out_width))\n",
    "    encoder_model.save(\"16C-%dx%d-encoder.h5\"%(in_height,in_width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = datagen.flow(x_test,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = next(it)\n",
    "cv2.imshow(\"Reconstructed\", decoded_imgs[0]/255) \n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = getImage('C:/Users/mayan/Desktop/tensorflow-autoencoder/static/pexels-photo-257840.jpeg')[0];\n",
    "#x_test = getImage(train_dir + 'IMG_20191018_232049.jpg')[0]\n",
    "#x_test = x_valid[4:5]\n",
    "\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n",
    "import sys\n",
    "\n",
    "decoded_imgs = encoder_model.predict(x_test)\n",
    "decoded_imgs = decoded_imgs/np.max(decoded_imgs) * 255\n",
    "decoded_imgs  = decoded_imgs.astype('uint8')\n",
    "\n",
    "decoded_imgs = decoder_model.predict(decoded_imgs)\n",
    "decoded_imgs = decoded_imgs/np.max(decoded_imgs)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Reconstructed\", decoded_imgs[0]) \n",
    "cv2.imshow(\"Original\", x_test[0]) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.save(\"encoder-final-model.h5\")\n",
    "decoder_model.save(\"decoder-final-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = os.listdir(\"C:/Users/mayan/Machine Learning/Datasets/Events/\")\n",
    "for file in train_files:\n",
    "    frame = cv2.imread(\"C:/Users/mayan/Machine Learning/Datasets/Events/\" + file,1)\n",
    "    try:\n",
    "        height, width, channels = frame.shape\n",
    "        if height >= in_height and width >= in_width:\n",
    "            X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = autoencoder.evaluate(x_test,x_test)\n",
    "#autoencoder.metrics_names\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'learning_rate': 2.9490101951523684e-05,\n",
    " 'beta_1': 0.8999999761581421,\n",
    " 'beta_2': 0.9990000128746033,\n",
    " 'decay': 0.0,\n",
    " 'epsilon': 1e-07,\n",
    " 'amsgrad': False}\n",
    "\"\"\"\n",
    "\n",
    "autoencoder.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save Model\n",
    "json= decoder_model.to_json()\n",
    "with open(\"decoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "\n",
    "decoder_model.save_weights(\"decoder.h5\")\n",
    "\n",
    "json= encoder_model.to_json()\n",
    "with open(\"encoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "encoder_model.save_weights(\"encoder.h5\")\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test,y_test = next(getData(16))\n",
    "x_valid,y_valid = getImage('C:/Users/mayan/Downloads/2-dog.jpg')\n",
    "#x_test,y_test = getImage('dark-fantasy-wallpapers-28123-6689698.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import imutils, time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "num_images = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "random_test_images = np.random.randint(x_valid.shape[0], size=min(num_images,x_valid.size))\n",
    "\n",
    "encoded_imgs = encoder_model.predict(x_valid)\n",
    "decoded_imgs = decoder_model.predict(encoded_imgs)\n",
    "\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(60, 50))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(3, num_images, i + 1)\n",
    "    plt.imshow(x_valid[image_idx])\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    cv2.imwrite(\"./real/%s.jpg\" %time.time(),x_valid[image_idx])\n",
    "    '''\n",
    "    # plot encoded image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    plt.imshow(encoded_imgs[image_idx].reshape(32, 16))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    '''\n",
    "    # plot reconstructed image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    name = time.time()\n",
    "    cv2.imwrite(\"./restructured/%s.jpg\" %name,decoded_imgs[image_idx] )\n",
    "    cv2.imwrite(\"./restructured/original-%s.jpg\" %name,x_valid[image_idx] )\n",
    "    plt.imshow(decoded_imgs[image_idx]/255)\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
