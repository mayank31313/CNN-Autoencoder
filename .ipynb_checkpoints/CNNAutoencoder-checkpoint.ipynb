{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import tensorflowjs as tfjs\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, Reshape, UpSampling2D, BatchNormalization, AveragePooling2D, Activation, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "#from keras import backend as K\n",
    "#import tensorflow as tf\n",
    "\n",
    "in_height = 360\n",
    "in_width =  640\n",
    "\n",
    "out_height = 720\n",
    "out_width = 1280\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 360, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 360, 640, 8)       224       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 180, 320, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 180, 320, 16)      1168      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 230400)            0         \n",
      "=================================================================\n",
      "Total params: 1,392\n",
      "Trainable params: 1,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 230400)            0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 90, 160, 8)        1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 180, 320, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 180, 320, 16)      1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 360, 640, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 360, 640, 32)      4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 720, 1280, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 720, 1280, 64)     18496     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 720, 1280, 3)      1731      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 720, 1280, 3)      0         \n",
      "=================================================================\n",
      "Total params: 27,195\n",
      "Trainable params: 27,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input =  Input(shape=(in_height,in_width,3))\n",
    "\n",
    "# Encoder Layers\n",
    "#autoencoder.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(28,28,1)))\n",
    "encoder = Conv2D(8, (3, 3), activation='relu' ,padding='same')(encoder_input)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(16, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "encoder =  Flatten(name='flatten_1')(encoder)\n",
    "encoder_model = Model(encoder_input,encoder)\n",
    "encoder_model.summary()\n",
    "#encoder_model.load_weights(\"8-encoder.h5\")\n",
    "#\n",
    "\n",
    "# Decoder Layers\n",
    "decoder_input = Input(shape=(115200*2,))\n",
    "#decoder = Dense(38400,activation=\"relu\",name='decoder_input')(decoder_input)\n",
    "decoder = Reshape(( 90, 160, 16))(decoder_input)\n",
    "decoder = Conv2D(8, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder =  UpSampling2D((2, 2),interpolation='bilinear')(decoder)\n",
    "decoder = Conv2D(16, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2),interpolation='bilinear')(decoder)\n",
    "decoder = Conv2D(32, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2),interpolation='bilinear')(decoder)\n",
    "decoder = Conv2D(64, (3, 3), padding='same',activation='relu')(decoder)\n",
    "decoder = Conv2D(3, (3, 3), padding='same',activation='relu')(decoder)\n",
    "decoder = Activation(activation='relu')(decoder)\n",
    "\n",
    "decoder_model = Model(decoder_input,decoder)\n",
    "decoder_model.summary()\n",
    "#decoder_model.load_weights(\"8-decoder.h5\")\n",
    "\n",
    "autoencoder = Model(encoder_input,decoder_model(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(autoencoder, './tensorflowjs-model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "\n",
    "dir_ = \"./../flickr30k_images/\"\n",
    "X = list()\n",
    "Y = list()\n",
    "files = os.listdir(dir_)\n",
    "\n",
    "def getImage(file):\n",
    "    #â€ªC:\\Users\\mayan\\Downloads\\2-dog.jpg\n",
    "    frame = cv2.imread(file,1)\n",
    "    return [np.array([cv2.resize(frame,(in_width,in_height))]),np.array([cv2.resize(frame,(out_width,out_height))])]\n",
    "\n",
    "def getData(batch_size=128):\n",
    "    while True:\n",
    "        for i , file in enumerate(files):\n",
    "            frame = cv2.imread(dir_ + file,1)\n",
    "            try:\n",
    "                Y.append(cv2.resize(frame,(out_width,out_height)))\n",
    "                X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "                if (i + 1) % batch_size == 0:\n",
    "                        yield (np.array(X),np.array(Y))\n",
    "                        X.clear()\n",
    "                        Y.clear()\n",
    "            except Exception as ex:\n",
    "                print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0915 14:51:28.852292  9020 deprecation_wrapper.py:119] From C:\\Users\\mayan\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0915 14:51:33.497732  9020 deprecation_wrapper.py:119] From C:\\Users\\mayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0915 14:51:33.868520  9020 deprecation_wrapper.py:119] From C:\\Users\\mayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102 samples, validate on 26 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import clear_output\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "\n",
    "#datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True,horizontal_flip=True,vertical_flip=True)\n",
    "# fit parameters from data\n",
    "#datagen.fit(frames)\n",
    "# configure batch size and retrieve one batch of images\n",
    "\n",
    "#autoencoder.compile(optimizer='adam', loss=vae_loss)\n",
    "#for X_, Y_ in datagen.flow(X,Y, batch_size=256):\n",
    "#autoencoder.fit_generator(getData(8),epochs=10,samples_per_epoch=50)\n",
    "#autoencoder.compile(optimizer='adam', loss='mean_absolute_error',metrics=['acc'])\n",
    "autoencoder.compile(optimizer='adam', loss='mse',metrics=['acc'])\n",
    "for X_, Y_ in getData(256):\n",
    "    #for X_D,Y_D in datagen.flow(X_,Y_,batch_size=128): \n",
    "    autoencoder.fit(X_, Y_,\n",
    "                epochs=10,\n",
    "                batch_size=8,validation_split=0.2)\n",
    "    clear_output()\n",
    "\n",
    "    json= decoder_model.to_json()\n",
    "    with open(\"9-decoder.json\", \"w\") as json_file:\n",
    "        json_file.write(json)\n",
    "\n",
    "    decoder_model.save(\"9-decoder.h5\")\n",
    "\n",
    "    json= encoder_model.to_json()\n",
    "    with open(\"9-encoder.json\", \"w\") as json_file:\n",
    "        json_file.write(json)\n",
    "    encoder_model.save(\"9-encoder.h5\")\n",
    "    \n",
    "    autoencoder.save('autoencoder-model-9-%dx%d-%dx%d.h5'%(in_height,in_width,out_height,out_width))\n",
    "    \n",
    "    print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save Model\n",
    "json= decoder_model.to_json()\n",
    "with open(\"decoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "\n",
    "decoder_model.save_weights(\"decoder.h5\")\n",
    "\n",
    "json= encoder_model.to_json()\n",
    "with open(\"encoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "encoder_model.save_weights(\"encoder.h5\")\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import imutils, time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "num_images = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "#x_test,y_test = next(getData(16))\n",
    "#x_test,y_test = getImage('C:/Users/mayan/Downloads/2-dog.jpg')\n",
    "x_test,y_test = getImage('dark-fantasy-wallpapers-28123-6689698.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_images = np.random.randint(y_test.shape[0], size=min(num_images,y_test.size))\n",
    "\n",
    "encoded_imgs = encoder_model.predict(x_test)\n",
    "decoded_imgs = decoder_model.predict(encoded_imgs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(60, 50))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(3, num_images, i + 1)\n",
    "    plt.imshow(y_test[image_idx])\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    cv2.imwrite(\"./real/%s.jpg\" %time.time(),y_test[image_idx])\n",
    "    '''\n",
    "    # plot encoded image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    plt.imshow(encoded_imgs[image_idx].reshape(32, 16))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    '''\n",
    "    # plot reconstructed image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    name = time.time()\n",
    "    cv2.imwrite(\"./restructured/%s.jpg\" %name,decoded_imgs[image_idx] )\n",
    "    cv2.imwrite(\"./restructured/original-%s.jpg\" %name,y_test[image_idx] )\n",
    "    plt.imshow(decoded_imgs[image_idx]/255)\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
