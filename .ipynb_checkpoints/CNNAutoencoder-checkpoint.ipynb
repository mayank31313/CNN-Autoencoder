{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import tensorflowjs as tfjs\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, Reshape, UpSampling2D, BatchNormalization, AveragePooling2D, Activation, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "#from keras import backend as K\n",
    "#import tensorflow as tf\n",
    "\n",
    "in_height = 360\n",
    "in_width =  640\n",
    "\n",
    "out_height = 712\n",
    "out_width = 1272\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 360, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 358, 638, 16)      448       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 179, 319, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 177, 317, 8)       1160      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 89, 159, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 113208)            0         \n",
      "=================================================================\n",
      "Total params: 1,608\n",
      "Trainable params: 1,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 22:34:57.369102  5304 deprecation_wrapper.py:119] From C:\\Users\\mayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0913 22:34:57.371101  5304 deprecation_wrapper.py:119] From C:\\Users\\mayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 113208)            0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 89, 159, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 89, 159, 64)       4672      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 178, 318, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 178, 318, 32)      18464     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 356, 636, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 356, 636, 16)      4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 712, 1272, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 712, 1272, 8)      1160      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 712, 1272, 3)      219       \n",
      "=================================================================\n",
      "Total params: 29,139\n",
      "Trainable params: 29,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input =  Input(shape=(in_height,in_width,3))\n",
    "\n",
    "# Encoder Layers\n",
    "#autoencoder.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(28,28,1)))\n",
    "encoder = Conv2D(16, (3, 3), activation='relu')(encoder_input)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(8, (3, 3), activation='relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "encoder =  Flatten(name='flatten_1')(encoder)\n",
    "encoder_model = Model(encoder_input,encoder)\n",
    "encoder_model.summary()\n",
    "encoder_model.load_weights(\"8-encoder.h5\")\n",
    "#\n",
    "\n",
    "# Decoder Layers\n",
    "decoder_input = Input(shape=(113208,))\n",
    "#decoder = Dense(38400,activation=\"relu\",name='decoder_input')(decoder_input)\n",
    "decoder = Reshape(( 89, 159, 8))(decoder_input)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder =  UpSampling2D((2, 2),interpolation='bilinear')(decoder)\n",
    "decoder = Conv2D(32, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2),interpolation='bilinear')(decoder)\n",
    "decoder = Conv2D(16, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2),interpolation='bilinear')(decoder)\n",
    "decoder = Conv2D(8, (3, 3), padding='same',activation='relu')(decoder)\n",
    "decoder = Conv2D(3, (3, 3), padding='same',activation='relu')(decoder)\n",
    "\n",
    "\n",
    "decoder_model = Model(decoder_input,decoder)\n",
    "decoder_model.summary()\n",
    "decoder_model.load_weights(\"8-decoder.h5\")\n",
    "\n",
    "autoencoder = Model(encoder_input,decoder_model(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(autoencoder, './tensorflowjs-model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "\n",
    "dir_ = \"./../flickr30k_images/\"\n",
    "X = list()\n",
    "Y = list()\n",
    "files = os.listdir(dir_)\n",
    "\n",
    "def getImage(file):\n",
    "    #â€ªC:\\Users\\mayan\\Downloads\\2-dog.jpg\n",
    "    frame = cv2.imread(file,1)\n",
    "    return [np.array([cv2.resize(frame,(width,height))]),np.array([cv2.resize(frame,(out_width,out_height))])]\n",
    "\n",
    "def getData(batch_size=128):\n",
    "    while True:\n",
    "        for i , file in enumerate(files):\n",
    "            frame = cv2.imread(dir_ + file,1)\n",
    "            try:\n",
    "                Y.append(cv2.resize(frame,(out_width,out_height)))\n",
    "                X.append(cv2.resize(frame,(width,height)))\n",
    "                if (i + 1) % batch_size == 0:\n",
    "                        yield (np.array(X),np.array(Y))\n",
    "                        X.clear()\n",
    "                        Y.clear()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "               \n",
    "            \"\"\"\n",
    "            capture = cv2.VideoCapture(\"C:/Users/mayan/Desktop/VID_20190731_103410.mp4\")\n",
    "            while capture.isOpened() :\n",
    "                et,frame = capture.read()\n",
    "                if et:\n",
    "                    Y.append(cv2.resize(frame,(480,640)))\n",
    "                    X.append(cv2.resize(frame,(240,320)))\n",
    "                else:\n",
    "                    break\n",
    "            capture.release()\n",
    "\n",
    "            import os\n",
    "            video_files= os.listdir('./Videos/')[:2]\n",
    "\n",
    "            for file in video_files:\n",
    "\n",
    "                capture = cv2.VideoCapture(\"./Videos/\" + file)\n",
    "                while capture.isOpened() :\n",
    "                    et,frame = capture.read()\n",
    "                    if et:\n",
    "                        Y.append(cv2.resize(frame,(480,640)))\n",
    "                        X.append(cv2.resize(frame,(240,320)))\n",
    "                    else:\n",
    "                        break\n",
    "                capture.release()\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 22:27:33.846839  5304 deprecation_wrapper.py:119] From C:\\Users\\mayan\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-98a6af1117b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_absolute_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m#for X_D,Y_D in datagen.flow(X_,Y_,batch_size=128):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     autoencoder.fit(X_, Y_,\n",
      "\u001b[1;32m<ipython-input-3-9d38a5eb14a3>\u001b[0m in \u001b[0;36mgetData\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import clear_output\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True,horizontal_flip=True,vertical_flip=True)\n",
    "# fit parameters from data\n",
    "#datagen.fit(frames)\n",
    "# configure batch size and retrieve one batch of images\n",
    "\n",
    "#autoencoder.compile(optimizer='adam', loss=vae_loss)\n",
    "#for X_, Y_ in datagen.flow(X,Y, batch_size=256):\n",
    "#autoencoder.fit_generator(getData(8),epochs=10,samples_per_epoch=50)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_absolute_error',metrics=['acc'])\n",
    "\n",
    "for X_, Y_ in getData(32):\n",
    "    #for X_D,Y_D in datagen.flow(X_,Y_,batch_size=128): \n",
    "    autoencoder.fit(X_, Y_,\n",
    "                epochs=10,\n",
    "                batch_size=8,validation_split=0.2)\n",
    "    clear_output()\n",
    "\n",
    "    json= decoder_model.to_json()\n",
    "    with open(\"8-decoder.json\", \"w\") as json_file:\n",
    "        json_file.write(json)\n",
    "\n",
    "    decoder_model.save_weights(\"8-decoder.h5\")\n",
    "\n",
    "    json= encoder_model.to_json()\n",
    "    with open(\"8-encoder.json\", \"w\") as json_file:\n",
    "        json_file.write(json)\n",
    "    encoder_model.save_weights(\"8-encoder.h5\")\n",
    "\n",
    "    print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save Model\n",
    "json= decoder_model.to_json()\n",
    "with open(\"decoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "\n",
    "decoder_model.save_weights(\"decoder.h5\")\n",
    "\n",
    "json= encoder_model.to_json()\n",
    "with open(\"encoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "encoder_model.save_weights(\"encoder.h5\")\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import imutils, time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "num_images = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "x_test,y_test = next(getData(16))\n",
    "#x_test,y_test = getImage('C:/Users/mayan/Downloads/2-dog.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_images = np.random.randint(y_test.shape[0], size=min(num_images,y_test.size))\n",
    "\n",
    "encoded_imgs = encoder_model.predict(x_test)\n",
    "decoded_imgs = decoder_model.predict(encoded_imgs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(60, 50))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(3, num_images, i + 1)\n",
    "    plt.imshow(y_test[image_idx])\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    cv2.imwrite(\"./real/%s.jpg\" %time.time(),y_test[image_idx])\n",
    "    '''\n",
    "    # plot encoded image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    plt.imshow(encoded_imgs[image_idx].reshape(32, 16))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    '''\n",
    "    # plot reconstructed image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    name = time.time()\n",
    "    cv2.imwrite(\"./restructured/%s.jpg\" %name,decoded_imgs[image_idx] )\n",
    "    cv2.imwrite(\"./restructured/original-%s.jpg\" %name,y_test[image_idx] )\n",
    "    plt.imshow(decoded_imgs[image_idx]/255)\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
