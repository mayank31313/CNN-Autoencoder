{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import tensorflowjs as tfjs\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, Reshape, UpSampling2D, BatchNormalization, AveragePooling2D, Activation, Lambda, Conv2DTranspose, ReLU\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import backend as K\n",
    "#import tensorflow as tf\n",
    "from keras.regularizers import l1\n",
    "\n",
    "in_height = 720//2\n",
    "in_width =  1280//2\n",
    "\n",
    "#out_height = 720\n",
    "#out_width = 1280\n",
    "\n",
    "out_height = in_height\n",
    "out_width = in_width\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'encoder/z_mean/BiasAdd:0' shape=(?, 2) dtype=float32>,\n",
       " <tf.Tensor 'encoder/z_log_var/BiasAdd:0' shape=(?, 2) dtype=float32>,\n",
       " <tf.Tensor 'encoder/z/add:0' shape=(?, 2) dtype=float32>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 360, 640, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 360, 640, 8)  224         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 360, 640, 8)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 180, 320, 8)  0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 180, 320, 16) 1168        average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 180, 320, 16) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 90, 160, 16)  0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 90, 160, 32)  4640        average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 90, 160, 32)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 45, 80, 32)   0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 115200)       0           average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 8)            921608      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 200)          1800        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 200)          1800        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 200)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 931,240\n",
      "Trainable params: 931,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 115200)            23155200  \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 45, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DT (None, 90, 160, 32)       9248      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 90, 160, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DT (None, 180, 320, 16)      4624      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 180, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DT (None, 360, 640, 8)       1160      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DT (None, 360, 640, 3)       27        \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 360, 640, 3)       0         \n",
      "=================================================================\n",
      "Total params: 23,170,259\n",
      "Trainable params: 23,170,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "latent_dim = 200\n",
    "\n",
    "encoder_input =  Input(shape=(in_height,in_width,3))\n",
    "\n",
    "# Encoder Layers\n",
    "encoder = Conv2D(8, (3, 3),padding='same', kernel_constraint=maxnorm(3))(encoder_input)\n",
    "encoder = Activation('relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same',)(encoder)\n",
    "encoder = Conv2D(16, (3, 3), padding='same', kernel_constraint=maxnorm(3))(encoder)\n",
    "encoder = Activation('relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "encoder = Conv2D(32, (3, 3), padding='same', kernel_constraint=maxnorm(3))(encoder)\n",
    "encoder = Activation('relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "shape = K.int_shape(encoder)\n",
    "encoder =  Flatten(name='flatten_1')(encoder)\n",
    "encoder = Dense(8, activation='relu')(encoder)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(encoder)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(encoder)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "encoder_model = Model(encoder_input, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder_model.summary()\n",
    "\n",
    "#encoder_model.load_weights(\"encoder-weights-360x640.h5\")\n",
    "\n",
    "# Decoder Layers\n",
    "decoder_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "decoder = Dense(shape[1] * shape[2] * shape[3], activation='relu')(decoder_inputs)\n",
    "decoder = Reshape((shape[1], shape[2], shape[3]))(decoder)\n",
    "\n",
    "decoder = Conv2DTranspose(32, (3, 3), padding='same',strides=2, kernel_constraint=maxnorm(3))(decoder)\n",
    "decoder = Activation('relu')(decoder)\n",
    "\n",
    "decoder = Conv2DTranspose(16, (3, 3), padding='same',strides=2, kernel_constraint=maxnorm(3))(decoder)\n",
    "decoder = Activation('relu')(decoder)\n",
    "\n",
    "decoder = Conv2DTranspose(8, (3, 3), padding='same',strides=2, kernel_constraint=maxnorm(3))(decoder)\n",
    "\n",
    "decoder = Conv2DTranspose(3, (1, 1), padding='same')(decoder)\n",
    "\n",
    "decoder = ReLU(max_value=255)(decoder)\n",
    "decoder_model = Model(decoder_inputs,decoder)\n",
    "decoder_model.summary()\n",
    "\n",
    "outputs = decoder_model(encoder_model(encoder_input)[2])\n",
    "\n",
    "autoencoder = Model(encoder_input, outputs, name='vae')\n",
    "autoencoder.compile(optimizer='adam',  loss='mean_absolute_error',metrics=['acc'])\n",
    "\n",
    "#autoencoder.load_weights('autoencoder-weights-model-13-360x640-360x640.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "train_dir = \"../Datasets/DIV2K_train_HR/\"\n",
    "valid_dir = \"../Datasets/DIV2K_valid_HR/\"\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "#files = pd.read_csv('image_data.csv').Path\n",
    "train_files = os.listdir(train_dir)\n",
    "valid_files = os.listdir(valid_dir)\n",
    "\n",
    "def getImage(file):\n",
    "    #â€ªC:\\Users\\mayan\\Downloads\\2-dog.jpg\n",
    "    frame = cv2.imread(file,1)\n",
    "    return [np.array([cv2.resize(frame,(in_width,in_height))]),np.array([cv2.resize(frame,(out_width,out_height))])]\n",
    "\n",
    "def getValidation():\n",
    "    x_valid,y_valid = [],[]   \n",
    "    for file in valid_files:\n",
    "        frame = cv2.imread(valid_dir + file,1)\n",
    "        try:\n",
    "            #y_valid.append(cv2.resize(frame,(out_width,out_height)))\n",
    "            x_valid.append(cv2.resize(frame,(in_width,in_height)))\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "    return np.array(x_valid),np.array(y_valid)\n",
    "\n",
    "\n",
    "for file in train_files:\n",
    "    frame = cv2.imread(train_dir + file,1)\n",
    "    try:\n",
    "        X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "\"\"\"\n",
    "train_files = os.listdir(\"C:/Users/mayan/Desktop/datasets/OutdoorSceneTrain_v2/mountain\")\n",
    "for file in train_files:\n",
    "    frame = cv2.imread(\"C:/Users/mayan/Desktop/datasets/OutdoorSceneTrain_v2/mountain/\" + file,1)\n",
    "    try:\n",
    "        height, width, channels = frame.shape\n",
    "        if height >= in_height and width >= in_width:\n",
    "            X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "train_files = os.listdir(\"./../Datasets/flickr30k_images/\")\n",
    "for file in train_files:\n",
    "    frame = cv2.imread( './../Datasets/flickr30k_images/'+ file,1)\n",
    "    try:\n",
    "        height, width, channels = frame.shape\n",
    "        if height >= in_height and width >= in_width:\n",
    "            X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\"\"\"        \n",
    "x_valid,y_valid = getValidation()\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90,brightness_range=[0.5,1.0],zoom_range=0.15,\n",
    "\t\twidth_shift_range=0.2,\n",
    "\t\theight_shift_range=0.2,fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Test Loss 0.23255537450313568\n",
      "Test Accuracy 0.25767794251441956\n",
      "Epoch 1/10\n",
      "376/376 [==============================] - 5s 14ms/step - loss: 0.1361 - acc: 0.4491\n",
      "Epoch 2/10\n",
      " 32/376 [=>............................] - ETA: 4s - loss: 0.1331 - acc: 0.4146"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7fe437e220b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     hist = autoencoder.fit(X_, X_,\n\u001b[0;32m     17\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 batch_size=32)\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    184\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0;32m    185\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "\n",
    "validation_accuracy = 0.7050989866256714\n",
    "learning_rate = (1-validation_accuracy)/10000\n",
    "#autoencoder.compile(optimizer=Adam(lr = learning_rate),  loss='mean_absolute_error',metrics=['acc'])\n",
    "\n",
    "#autoencoder.compile(optimizer=Adam(lr = 2.9490101951523684e-05),  loss='mse',metrics=['acc'])\n",
    "it = datagen.flow(X,batch_size=512,shuffle = True)\n",
    "\n",
    "x_test = getImage('C:/Users/mayan/Downloads/2-dog.jpg')[0]/255;\n",
    "\n",
    "for i in range(1000):\n",
    "    X_ = next(it) \n",
    "    X_/=255\n",
    "    hist = autoencoder.fit(X_, X_, \n",
    "                epochs=10,\n",
    "                batch_size=32)\n",
    "    clear_output() \n",
    "    \n",
    "    decoded_imgs = autoencoder.predict(x_test) \n",
    "    h = autoencoder.evaluate(x_test,x_test)\n",
    "        \n",
    "    #print(\"Validation Loss\",np.mean(hist.history['val_loss']))\n",
    "    #print(\"Validation Accuracy\",np.mean(hist.history['val_acc']))   \n",
    "    \n",
    "    print(\"Test Loss\",h[0])\n",
    "    print(\"Test Accuracy\",h[1])\n",
    "    \n",
    "    cv2.imwrite(\"./restructured/test_image.jpg\" ,decoded_imgs[0])\n",
    "    cv2.imwrite(\"./restructured/original-test_image.jpg\" ,x_test[0])\n",
    "    \n",
    "    #decoder_model.save(\"%dx%d-decoder.h5\"%(out_height,out_width))\n",
    "    #encoder_model.save(\"%dx%d-encoder.h5\"%(in_height,in_width))\n",
    "    autoencoder.save_weights(\"vae-autoencoder-weights-model-13-360x640-360x640.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights(\"autoencoder-weights-model-13-360x640-360x640.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Test Loss 0.2088358849287033\n",
      "Test Accuracy 0.4183333218097687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = getImage('C:/Users/mayan/Desktop/tensorflow-autoencoder/static/pexels-photo-257840.jpeg')[0]/255;\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "h = autoencoder.evaluate(x_test,x_test)\n",
    "\n",
    "print(\"Test Loss\",h[0])\n",
    "print(\"Test Accuracy\",h[1])\n",
    "\n",
    "cv2.imwrite(\"./restructured/test_image.jpg\" ,decoded_imgs[0] * 255)\n",
    "cv2.imwrite(\"./restructured/original-test_image.jpg\" ,x_test[0] * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = os.listdir(\"C:/Users/mayan/Machine Learning/Datasets/Events/\")\n",
    "for file in train_files:\n",
    "    frame = cv2.imread(\"C:/Users/mayan/Machine Learning/Datasets/Events/\" + file,1)\n",
    "    try:\n",
    "        height, width, channels = frame.shape\n",
    "        if height >= in_height and width >= in_width:\n",
    "            X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = autoencoder.evaluate(x_test,x_test)\n",
    "#autoencoder.metrics_names\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'learning_rate': 2.9490101951523684e-05,\n",
    " 'beta_1': 0.8999999761581421,\n",
    " 'beta_2': 0.9990000128746033,\n",
    " 'decay': 0.0,\n",
    " 'epsilon': 1e-07,\n",
    " 'amsgrad': False}\n",
    "\"\"\"\n",
    "\n",
    "autoencoder.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save Model\n",
    "json= decoder_model.to_json()\n",
    "with open(\"decoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "\n",
    "decoder_model.save_weights(\"decoder.h5\")\n",
    "\n",
    "json= encoder_model.to_json()\n",
    "with open(\"encoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "encoder_model.save_weights(\"encoder.h5\")\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test,y_test = next(getData(16))\n",
    "x_valid,y_valid = getImage('C:/Users/mayan/Downloads/2-dog.jpg')\n",
    "#x_test,y_test = getImage('dark-fantasy-wallpapers-28123-6689698.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import imutils, time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "num_images = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "random_test_images = np.random.randint(x_valid.shape[0], size=min(num_images,x_valid.size))\n",
    "\n",
    "encoded_imgs = encoder_model.predict(x_valid)\n",
    "decoded_imgs = decoder_model.predict(encoded_imgs)\n",
    "\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(60, 50))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(3, num_images, i + 1)\n",
    "    plt.imshow(x_valid[image_idx])\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    cv2.imwrite(\"./real/%s.jpg\" %time.time(),x_valid[image_idx])\n",
    "    '''\n",
    "    # plot encoded image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    plt.imshow(encoded_imgs[image_idx].reshape(32, 16))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    '''\n",
    "    # plot reconstructed image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    name = time.time()\n",
    "    cv2.imwrite(\"./restructured/%s.jpg\" %name,decoded_imgs[image_idx] )\n",
    "    cv2.imwrite(\"./restructured/original-%s.jpg\" %name,x_valid[image_idx] )\n",
    "    plt.imshow(decoded_imgs[image_idx]/255)\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
