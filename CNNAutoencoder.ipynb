{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, Reshape, UpSampling2D, BatchNormalization, AveragePooling2D, Activation, Lambda, Conv2DTranspose, ReLU\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l1\n",
    "\n",
    "in_height = 720//2\n",
    "in_width =  1280//2\n",
    "\n",
    "#out_height = 720\n",
    "#out_width = 1280\n",
    "\n",
    "out_height = in_height\n",
    "out_width = in_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 360, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 360, 640, 8)       224       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 360, 640, 8)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 180, 320, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 180, 320, 16)      1168      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 180, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 90, 160, 16)       2320      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 45, 80, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "=================================================================\n",
      "Total params: 3,712\n",
      "Trainable params: 3,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 45, 80, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 90, 160, 16)       2320      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 180, 320, 16)      2320      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 180, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 360, 640, 8)       1160      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 360, 640, 3)       27        \n",
      "=================================================================\n",
      "Total params: 5,827\n",
      "Trainable params: 5,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.losses import *\n",
    "encoder_input =  Input(shape=(in_height,in_width,3))\n",
    "\n",
    "max_norm = 3\n",
    "# Encoder Layers\n",
    "encoder = Conv2D(8, (3, 3),padding='same', kernel_constraint=maxnorm(max_norm))(encoder_input)\n",
    "encoder = Activation('relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same',)(encoder)\n",
    "encoder = Conv2D(16, (3, 3), padding='same', kernel_constraint=maxnorm(max_norm))(encoder)\n",
    "encoder = Activation('relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "encoder = Conv2D(16, (3, 3), padding='same', kernel_constraint=maxnorm(max_norm))(encoder)\n",
    "encoder = Activation('relu')(encoder)\n",
    "encoder = AveragePooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "encoder =  Flatten(name='flatten_1')(encoder)\n",
    "\n",
    "encoder_model = Model(encoder_input,encoder)\n",
    "encoder_model.summary()\n",
    "\n",
    "#encoder_model.load_weights(\"16C-360x640-encoder.h5\")\n",
    "\n",
    "# Decoder Layers\n",
    "decoder_input = Input(shape=(45 * 80 * 16,))\n",
    "decoder = Reshape(( 45, 80, 16))(decoder_input)\n",
    "decoder = Conv2DTranspose(16, (3, 3), padding='same',strides=2, kernel_constraint=maxnorm(max_norm))(decoder)\n",
    "decoder = Activation('relu')(decoder)\n",
    "decoder = Conv2DTranspose(16, (3, 3), padding='same',strides=2, kernel_constraint=maxnorm(max_norm))(decoder)\n",
    "decoder = Activation('relu')(decoder)\n",
    "decoder = Conv2DTranspose(8, (3, 3), padding='same',strides=2, kernel_constraint=maxnorm(max_norm))(decoder)\n",
    "decoder = Conv2DTranspose(3, (1, 1), padding='same')(decoder)\n",
    "\n",
    "#decoder = ReLU(max_value=255)(decoder)\n",
    "decoder_model = Model(decoder_input,decoder)\n",
    "decoder_model.summary()\n",
    "\n",
    "autoencoder = Model(encoder_input,decoder_model(encoder))\n",
    "autoencoder.compile(optimizer='adam',  loss=logcosh,metrics=['acc'])\n",
    "\n",
    "autoencoder.load_weights('weights-improvement-01-0.85.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayan\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 360, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 360, 640, 8)       224       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 360, 640, 8)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_16 (Averag (None, 180, 320, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 180, 320, 16)      1168      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 180, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_17 (Averag (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 90, 160, 16)       2320      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 90, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_18 (Averag (None, 45, 80, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "model_13 (Model)             (None, 360, 640, 3)       5827      \n",
      "=================================================================\n",
      "Total params: 9,539\n",
      "Trainable params: 9,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "encoder_model = load_model(\"16C-360x640-encoder.h5\")\n",
    "decoder_model = load_model(\"16C-360x640-decoder.h5\")\n",
    "\n",
    "autoencoder = Model(encoder_model.inputs,decoder_model(encoder_model.outputs))\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer='adam',  loss=logcosh,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(autoencoder, './tensorflowjs-model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "train_dir = \"../Datasets/DIV2K_train_HR/\"\n",
    "valid_dir = \"../Datasets/DIV2K_valid_HR/\"\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "#files = pd.read_csv('image_data.csv').Path\n",
    "train_files = os.listdir(train_dir)\n",
    "valid_files = os.listdir(valid_dir)\n",
    "\n",
    "def getImage(file):\n",
    "    #â€ªC:\\Users\\mayan\\Downloads\\2-dog.jpg\n",
    "    frame = cv2.imread(file,1)\n",
    "    return [np.array([cv2.resize(frame,(in_width,in_height))]),np.array([cv2.resize(frame,(out_width,out_height))])]\n",
    "\n",
    "def getValidation():\n",
    "    x_valid,y_valid = [],[]   \n",
    "    for file in valid_files:\n",
    "        frame = cv2.imread(valid_dir + file,1)\n",
    "        try:\n",
    "            #y_valid.append(cv2.resize(frame,(out_width,out_height)))\n",
    "            x_valid.append(cv2.resize(frame,(in_width,in_height)))\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "    return np.array(x_valid),np.array(y_valid)\n",
    "\n",
    "\"\"\"\n",
    "for file in train_files:\n",
    "    frame = cv2.imread(train_dir + file,1)\n",
    "    try:\n",
    "        X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\"\"\"\n",
    "x_valid,y_valid = getValidation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_output = encoder_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"images.npy\",X)\n",
    "np.save(\"encoded_output.npy\",encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'shape'\n",
      "'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(\"./../Datasets/flickr30k_images/\")\n",
    "for file in train_files:\n",
    "    frame = cv2.imread( './../Datasets/flickr30k_images/'+ file,1)\n",
    "    try:\n",
    "        height, width, channels = frame.shape\n",
    "        if height >= in_height and width >= in_width:\n",
    "            X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5874 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        'D:\\\\Fast and Furious',\n",
    "        target_size=(in_height, in_width),\n",
    "        batch_size=1,\n",
    "        class_mode=\"input\")\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 245s 42ms/step - loss: 4.7443 - acc: 0.8697 - val_loss: 11.6578 - val_acc: 0.8305\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85182\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.1644163131713867\n",
      "Test Accuracy 0.8966232538223267\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 245s 42ms/step - loss: 4.7430 - acc: 0.8688 - val_loss: 12.5837 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85182\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 4.6901140213012695\n",
      "Test Accuracy 0.8349696397781372\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.7273 - acc: 0.8665 - val_loss: 11.8953 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85182\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.6114280223846436\n",
      "Test Accuracy 0.8139366507530212\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 242s 41ms/step - loss: 4.7139 - acc: 0.8700 - val_loss: 11.6329 - val_acc: 0.8479\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85182\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.21777081489563\n",
      "Test Accuracy 0.8815451264381409\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.7223 - acc: 0.8718 - val_loss: 11.8677 - val_acc: 0.8458\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85182\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.856304883956909\n",
      "Test Accuracy 0.7779861092567444\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.6996 - acc: 0.8683 - val_loss: 11.5060 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.85182 to 0.85189, saving model to weights-improvement-01-0.85.hdf5\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 2.9935085773468018\n",
      "Test Accuracy 0.9337586760520935\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.7032 - acc: 0.8707 - val_loss: 12.6613 - val_acc: 0.8252\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85189\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 4.49485445022583\n",
      "Test Accuracy 0.8041796684265137\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.7332 - acc: 0.8698 - val_loss: 12.2680 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85189\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.9863481521606445\n",
      "Test Accuracy 0.7571397423744202\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.6659 - acc: 0.8707 - val_loss: 26.4874 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85189\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 20.34684181213379\n",
      "Test Accuracy 0.8225347399711609\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.7461 - acc: 0.8711 - val_loss: 13.1125 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85189\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 5.556450843811035\n",
      "Test Accuracy 0.8923307061195374\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.6769 - acc: 0.8709 - val_loss: 11.3582 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.85189 to 0.85983, saving model to weights-improvement-01-0.86.hdf5\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 2.729048013687134\n",
      "Test Accuracy 0.9403992891311646\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.6881 - acc: 0.8704 - val_loss: 14.7316 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 9.547728538513184\n",
      "Test Accuracy 0.8497482538223267\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.7126 - acc: 0.8699 - val_loss: 12.0301 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.348337173461914\n",
      "Test Accuracy 0.8930816054344177\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 41ms/step - loss: 4.6710 - acc: 0.8712 - val_loss: 11.9062 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.7585926055908203\n",
      "Test Accuracy 0.821323812007904\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 243s 41ms/step - loss: 4.6372 - acc: 0.8721 - val_loss: 11.8141 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.314452648162842\n",
      "Test Accuracy 0.9115495085716248\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.6111 - acc: 0.8728 - val_loss: 12.6239 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.6356148719787598\n",
      "Test Accuracy 0.8689409494400024\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.6374 - acc: 0.8705 - val_loss: 11.7941 - val_acc: 0.8185\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Test Loss 3.7969789505004883\n",
      "Test Accuracy 0.8986241221427917\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.6995 - acc: 0.8743 - val_loss: 13.2408 - val_acc: 0.7636\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 5.792318820953369\n",
      "Test Accuracy 0.8606597185134888\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.6909 - acc: 0.8671 - val_loss: 11.5896 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.360797643661499\n",
      "Test Accuracy 0.8909679055213928\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.6608 - acc: 0.8728 - val_loss: 11.5249 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.1615397930145264\n",
      "Test Accuracy 0.9018098711967468\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.7034 - acc: 0.8688 - val_loss: 12.8405 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 4.753878116607666\n",
      "Test Accuracy 0.9245529770851135\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 41ms/step - loss: 4.6301 - acc: 0.8683 - val_loss: 11.7109 - val_acc: 0.8443\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.3700051307678223\n",
      "Test Accuracy 0.9207118153572083\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.6574 - acc: 0.8692 - val_loss: 13.2126 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 6.4626874923706055\n",
      "Test Accuracy 0.8647222518920898\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.7030 - acc: 0.8706 - val_loss: 11.3720 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 2.7392003536224365\n",
      "Test Accuracy 0.9353775978088379\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.6056 - acc: 0.8676 - val_loss: 11.7180 - val_acc: 0.8259\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.4639182090759277\n",
      "Test Accuracy 0.9046918153762817\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 244s 42ms/step - loss: 4.5985 - acc: 0.8711 - val_loss: 11.3204 - val_acc: 0.8399\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 2.739469289779663\n",
      "Test Accuracy 0.9104427099227905\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 245s 42ms/step - loss: 4.6325 - acc: 0.8706 - val_loss: 11.5866 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.3580338954925537\n",
      "Test Accuracy 0.8627213835716248\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 245s 42ms/step - loss: 4.6247 - acc: 0.8714 - val_loss: 11.7506 - val_acc: 0.8392\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.0379109382629395\n",
      "Test Accuracy 0.9028428792953491\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 245s 42ms/step - loss: 4.6288 - acc: 0.8665 - val_loss: 12.0133 - val_acc: 0.8423\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Test Loss 3.499814510345459\n",
      "Test Accuracy 0.9190104007720947\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 246s 42ms/step - loss: 4.6236 - acc: 0.8649 - val_loss: 11.4360 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 2.899869203567505\n",
      "Test Accuracy 0.8857812285423279\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 250s 43ms/step - loss: 4.6241 - acc: 0.8729 - val_loss: 11.8358 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.2056868076324463\n",
      "Test Accuracy 0.91796875\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 248s 42ms/step - loss: 4.5690 - acc: 0.8755 - val_loss: 13.4903 - val_acc: 0.6169\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 5.95321798324585\n",
      "Test Accuracy 0.7083941102027893\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 248s 42ms/step - loss: 4.6111 - acc: 0.8702 - val_loss: 11.7324 - val_acc: 0.8162\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Test Loss 3.354881525039673\n",
      "Test Accuracy 0.9238237738609314\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 249s 42ms/step - loss: 4.5696 - acc: 0.8715 - val_loss: 11.7057 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 2.9257795810699463\n",
      "Test Accuracy 0.9240928888320923\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 247s 42ms/step - loss: 4.6040 - acc: 0.8760 - val_loss: 11.6967 - val_acc: 0.8304\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.249337673187256\n",
      "Test Accuracy 0.9144834876060486\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 248s 42ms/step - loss: 4.6077 - acc: 0.8802 - val_loss: 11.5133 - val_acc: 0.8355\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.289679527282715\n",
      "Test Accuracy 0.9010850787162781\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 248s 42ms/step - loss: 4.6242 - acc: 0.8777 - val_loss: 11.4518 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.1193268299102783\n",
      "Test Accuracy 0.8183550238609314\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 247s 42ms/step - loss: 4.5686 - acc: 0.8796 - val_loss: 11.6773 - val_acc: 0.8142\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.374711275100708\n",
      "Test Accuracy 0.8275824785232544\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 248s 42ms/step - loss: 4.6490 - acc: 0.8817 - val_loss: 11.3064 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 2.6809868812561035\n",
      "Test Accuracy 0.934448778629303\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 249s 42ms/step - loss: 4.6038 - acc: 0.8646 - val_loss: 11.4107 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 2.927689790725708\n",
      "Test Accuracy 0.9392665028572083\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 248s 42ms/step - loss: 4.5601 - acc: 0.8799 - val_loss: 11.4425 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Test Loss 2.8024492263793945\n",
      "Test Accuracy 0.9339409470558167\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 261s 44ms/step - loss: 4.6265 - acc: 0.8825 - val_loss: 11.3465 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Test Loss 2.9297802448272705\n",
      "Test Accuracy 0.9238237738609314\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 260s 44ms/step - loss: 4.5788 - acc: 0.8761 - val_loss: 11.5309 - val_acc: 0.8454\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Test Loss 3.0160014629364014\n",
      "Test Accuracy 0.8633506894111633\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 250s 43ms/step - loss: 4.5889 - acc: 0.8786 - val_loss: 11.3247 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 2.707798957824707\n",
      "Test Accuracy 0.9303732514381409\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 250s 43ms/step - loss: 4.5423 - acc: 0.8840 - val_loss: 11.6663 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85983\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.316263198852539\n",
      "Test Accuracy 0.8893923759460449\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 248s 42ms/step - loss: 4.5605 - acc: 0.8869 - val_loss: 11.3312 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.85983 to 0.86179, saving model to weights-improvement-01-0.86.hdf5\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 2.768890619277954\n",
      "Test Accuracy 0.936193585395813\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 249s 42ms/step - loss: 4.6205 - acc: 0.8806 - val_loss: 11.7106 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.4985692501068115\n",
      "Test Accuracy 0.8832986354827881\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 248s 42ms/step - loss: 4.6036 - acc: 0.8769 - val_loss: 12.4047 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 4.613848686218262\n",
      "Test Accuracy 0.938281238079071\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 249s 42ms/step - loss: 4.5487 - acc: 0.8684 - val_loss: 11.5822 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.118898630142212\n",
      "Test Accuracy 0.8926302194595337\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 249s 42ms/step - loss: 4.5800 - acc: 0.8819 - val_loss: 12.4143 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Test Loss 3.549474000930786\n",
      "Test Accuracy 0.9108376502990723\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 249s 42ms/step - loss: 4.5825 - acc: 0.8739 - val_loss: 11.8927 - val_acc: 0.7104\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.513615369796753\n",
      "Test Accuracy 0.8258029222488403\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 251s 43ms/step - loss: 4.5999 - acc: 0.8814 - val_loss: 11.8409 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.8799889087677\n",
      "Test Accuracy 0.8544270992279053\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 249s 42ms/step - loss: 4.5945 - acc: 0.8808 - val_loss: 11.6621 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.27781081199646\n",
      "Test Accuracy 0.8834765553474426\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 249s 42ms/step - loss: 4.5883 - acc: 0.8825 - val_loss: 12.8486 - val_acc: 0.8153\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Test Loss 5.736145973205566\n",
      "Test Accuracy 0.7241362929344177\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 250s 42ms/step - loss: 4.5179 - acc: 0.8859 - val_loss: 11.4466 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.2364203929901123\n",
      "Test Accuracy 0.9299435615539551\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 250s 43ms/step - loss: 4.5786 - acc: 0.8819 - val_loss: 11.7586 - val_acc: 0.8433\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.7197234630584717\n",
      "Test Accuracy 0.8451519012451172\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 251s 43ms/step - loss: 4.5731 - acc: 0.8824 - val_loss: 12.3556 - val_acc: 0.8209\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 4.28601598739624\n",
      "Test Accuracy 0.8488454818725586\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 251s 43ms/step - loss: 4.5343 - acc: 0.8804 - val_loss: 11.9197 - val_acc: 0.8268\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Test Loss 3.4652678966522217\n",
      "Test Accuracy 0.8924044966697693\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 250s 43ms/step - loss: 4.5540 - acc: 0.8745 - val_loss: 11.7523 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.324936866760254\n",
      "Test Accuracy 0.8691796660423279\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 251s 43ms/step - loss: 4.5544 - acc: 0.8779 - val_loss: 12.0775 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 4.311587810516357\n",
      "Test Accuracy 0.874474823474884\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 251s 43ms/step - loss: 4.5171 - acc: 0.8872 - val_loss: 12.1223 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Test Loss 3.9294240474700928\n",
      "Test Accuracy 0.877916693687439\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 251s 43ms/step - loss: 4.5722 - acc: 0.8789 - val_loss: 11.6065 - val_acc: 0.8409\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.2294602394104004\n",
      "Test Accuracy 0.8746614456176758\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 250s 43ms/step - loss: 4.5893 - acc: 0.8748 - val_loss: 11.5264 - val_acc: 0.8137\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.1645865440368652\n",
      "Test Accuracy 0.8783854246139526\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 252s 43ms/step - loss: 4.6442 - acc: 0.8777 - val_loss: 11.8731 - val_acc: 0.8401\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Test Loss 3.4662561416625977\n",
      "Test Accuracy 0.9330989718437195\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 254s 43ms/step - loss: 4.5329 - acc: 0.8812 - val_loss: 11.8921 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 4.064059734344482\n",
      "Test Accuracy 0.8664757013320923\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 252s 43ms/step - loss: 4.5571 - acc: 0.8843 - val_loss: 12.5017 - val_acc: 0.7852\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 4.635977745056152\n",
      "Test Accuracy 0.7405121326446533\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 255s 43ms/step - loss: 4.6102 - acc: 0.8876 - val_loss: 11.4971 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.114305257797241\n",
      "Test Accuracy 0.9194878339767456\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 260s 44ms/step - loss: 4.5830 - acc: 0.8795 - val_loss: 12.9930 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 4.681380271911621\n",
      "Test Accuracy 0.8573567867279053\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 263s 45ms/step - loss: 4.6371 - acc: 0.8831 - val_loss: 11.3868 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Test Loss 3.059357166290283\n",
      "Test Accuracy 0.9016232490539551\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 253s 43ms/step - loss: 4.5930 - acc: 0.8818 - val_loss: 11.6664 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.0230443477630615\n",
      "Test Accuracy 0.9162933826446533\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 253s 43ms/step - loss: 4.5384 - acc: 0.8812 - val_loss: 12.4284 - val_acc: 0.8361\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 4.242467880249023\n",
      "Test Accuracy 0.8690798878669739\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 246s 42ms/step - loss: 4.5842 - acc: 0.8795 - val_loss: 14.5205 - val_acc: 0.7995\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 8.66164493560791\n",
      "Test Accuracy 0.8661110997200012\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 245s 42ms/step - loss: 4.6753 - acc: 0.8777 - val_loss: 11.5662 - val_acc: 0.8493\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.103673219680786\n",
      "Test Accuracy 0.9374218583106995\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 246s 42ms/step - loss: 4.5529 - acc: 0.8759 - val_loss: 11.7365 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.5032849311828613\n",
      "Test Accuracy 0.8499913215637207\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 252s 43ms/step - loss: 4.5785 - acc: 0.8796 - val_loss: 11.7873 - val_acc: 0.7977\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Test Loss 3.8348045349121094\n",
      "Test Accuracy 0.85721355676651\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 253s 43ms/step - loss: 4.5710 - acc: 0.8681 - val_loss: 11.7052 - val_acc: 0.8469\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 4.0365095138549805\n",
      "Test Accuracy 0.8885242938995361\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 252s 43ms/step - loss: 4.5640 - acc: 0.8845 - val_loss: 12.1984 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 4.631653785705566\n",
      "Test Accuracy 0.8552430272102356\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 255s 43ms/step - loss: 4.5786 - acc: 0.8718 - val_loss: 11.6156 - val_acc: 0.8227\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.3301877975463867\n",
      "Test Accuracy 0.8741840124130249\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 255s 43ms/step - loss: 4.5933 - acc: 0.8779 - val_loss: 13.2549 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 6.154438018798828\n",
      "Test Accuracy 0.7984505295753479\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 261s 44ms/step - loss: 4.5344 - acc: 0.8852 - val_loss: 12.7467 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 5.616044998168945\n",
      "Test Accuracy 0.8452951312065125\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 265s 45ms/step - loss: 4.5589 - acc: 0.8789 - val_loss: 12.1403 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Test Loss 3.660698890686035\n",
      "Test Accuracy 0.9391536712646484\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 249s 42ms/step - loss: 4.5113 - acc: 0.8704 - val_loss: 11.4122 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Test Loss 2.9891624450683594\n",
      "Test Accuracy 0.9322048425674438\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 253s 43ms/step - loss: 4.5788 - acc: 0.8851 - val_loss: 11.4802 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test Loss 3.139249324798584\n",
      "Test Accuracy 0.8959331512451172\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 253s 43ms/step - loss: 4.5887 - acc: 0.8805 - val_loss: 12.6884 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Test Loss 3.891739845275879\n",
      "Test Accuracy 0.9232769012451172\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 251s 43ms/step - loss: 4.6047 - acc: 0.8844 - val_loss: 11.5620 - val_acc: 0.8499\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.4677836894989014\n",
      "Test Accuracy 0.805577278137207\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 251s 43ms/step - loss: 4.5669 - acc: 0.8771 - val_loss: 11.5720 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Test Loss 3.1074798107147217\n",
      "Test Accuracy 0.8751345276832581\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 250s 43ms/step - loss: 4.5815 - acc: 0.8774 - val_loss: 12.6853 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 5.3586835861206055\n",
      "Test Accuracy 0.7299913167953491\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 251s 43ms/step - loss: 4.5895 - acc: 0.8813 - val_loss: 11.5743 - val_acc: 0.8149\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.2829530239105225\n",
      "Test Accuracy 0.8903472423553467\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 252s 43ms/step - loss: 4.5559 - acc: 0.8807 - val_loss: 11.4723 - val_acc: 0.8427\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 3.1227400302886963\n",
      "Test Accuracy 0.9305468797683716\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 252s 43ms/step - loss: 4.6079 - acc: 0.8792 - val_loss: 12.1064 - val_acc: 0.7910\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Test Loss 4.088862895965576\n",
      "Test Accuracy 0.7869054079055786\n",
      "Epoch 1/1\n",
      "5874/5874 [==============================] - 252s 43ms/step - loss: 4.5341 - acc: 0.8800 - val_loss: 11.6227 - val_acc: 0.7863\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.86179\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Test Loss 3.6749560832977295\n",
      "Test Accuracy 0.8548914790153503\n",
      "Epoch 1/1\n",
      "1414/5874 [======>.......................] - ETA: 3:17 - loss: 4.6924 - acc: 0.8806"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "\n",
    "validation_accuracy = 0.7050989866256714\n",
    "learning_rate = (1-validation_accuracy)/10000\n",
    "\n",
    "#it = datagen.flow(np.array(X),batch_size=512,shuffle = True)\n",
    "\n",
    "x_test = getImage('C:/Users/mayan/Desktop/tensorflow-autoencoder/static/pexels-photo-257840.jpeg')[0];\n",
    "\n",
    "while True:\n",
    "    \"\"\"\n",
    "    X_ = next(train_generator)[0]  \n",
    "    hist = autoencoder.fit(X_,\n",
    "                epochs=10,\n",
    "                batch_size=8,validation_data = (x_valid,x_valid))\n",
    "    \"\"\"\n",
    "    autoencoder.fit_generator(train_generator,steps_per_epoch=5874,validation_data=(x_valid,x_valid),epochs=1,callbacks=[checkpoint])\n",
    "    \n",
    "    decoded_imgs = autoencoder.predict(x_test)\n",
    "    h = autoencoder.evaluate(x_test,x_test)\n",
    "    \n",
    "    print(\"Test Loss\",h[0])\n",
    "    print(\"Test Accuracy\",h[1])\n",
    "    \n",
    "    cv2.imwrite(\"./restructured/test_image.jpg\" ,decoded_imgs[0])\n",
    "    cv2.imwrite(\"./restructured/original-test_image.jpg\" ,x_test[0])\n",
    "    \n",
    "    decoder_model.save(\"16C-%dx%d-decoder.h5\"%(out_height,out_width))\n",
    "    encoder_model.save(\"16C-%dx%d-encoder.h5\"%(in_height,in_width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = datagen.flow(x_test,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = next(it)\n",
    "cv2.imshow(\"Reconstructed\", decoded_imgs[0]/255) \n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = getImage('C:/Users/mayan/Desktop/tensorflow-autoencoder/static/pexels-photo-257840.jpeg')[0];\n",
    "#x_test = getImage(train_dir + 'IMG_20191018_232049.jpg')[0]\n",
    "#x_test = x_valid[4:5]\n",
    "\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n",
    "import sys\n",
    "\n",
    "decoded_imgs = encoder_model.predict(x_test)\n",
    "decoded_imgs = decoded_imgs/np.max(decoded_imgs) * 255\n",
    "decoded_imgs  = decoded_imgs.astype('uint8')\n",
    "\n",
    "decoded_imgs = decoder_model.predict(decoded_imgs)\n",
    "decoded_imgs = decoded_imgs/np.max(decoded_imgs)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Reconstructed\", decoded_imgs[0]) \n",
    "cv2.imshow(\"Original\", x_test[0]) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.save(\"encoder-final-model.h5\")\n",
    "decoder_model.save(\"decoder-final-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = os.listdir(\"C:/Users/mayan/Machine Learning/Datasets/Events/\")\n",
    "for file in train_files:\n",
    "    frame = cv2.imread(\"C:/Users/mayan/Machine Learning/Datasets/Events/\" + file,1)\n",
    "    try:\n",
    "        height, width, channels = frame.shape\n",
    "        if height >= in_height and width >= in_width:\n",
    "            X.append(cv2.resize(frame,(in_width,in_height)))\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = autoencoder.evaluate(x_test,x_test)\n",
    "#autoencoder.metrics_names\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'learning_rate': 2.9490101951523684e-05,\n",
    " 'beta_1': 0.8999999761581421,\n",
    " 'beta_2': 0.9990000128746033,\n",
    " 'decay': 0.0,\n",
    " 'epsilon': 1e-07,\n",
    " 'amsgrad': False}\n",
    "\"\"\"\n",
    "\n",
    "autoencoder.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save Model\n",
    "json= decoder_model.to_json()\n",
    "with open(\"decoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "\n",
    "decoder_model.save_weights(\"decoder.h5\")\n",
    "\n",
    "json= encoder_model.to_json()\n",
    "with open(\"encoder.json\", \"w\") as json_file:\n",
    "    json_file.write(json)\n",
    "encoder_model.save_weights(\"encoder.h5\")\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test,y_test = next(getData(16))\n",
    "x_valid,y_valid = getImage('C:/Users/mayan/Downloads/2-dog.jpg')\n",
    "#x_test,y_test = getImage('dark-fantasy-wallpapers-28123-6689698.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import imutils, time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "num_images = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "random_test_images = np.random.randint(x_valid.shape[0], size=min(num_images,x_valid.size))\n",
    "\n",
    "encoded_imgs = encoder_model.predict(x_valid)\n",
    "decoded_imgs = decoder_model.predict(encoded_imgs)\n",
    "\n",
    "#decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(60, 50))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(3, num_images, i + 1)\n",
    "    plt.imshow(x_valid[image_idx])\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    cv2.imwrite(\"./real/%s.jpg\" %time.time(),x_valid[image_idx])\n",
    "    '''\n",
    "    # plot encoded image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    plt.imshow(encoded_imgs[image_idx].reshape(32, 16))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    '''\n",
    "    # plot reconstructed image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    name = time.time()\n",
    "    cv2.imwrite(\"./restructured/%s.jpg\" %name,decoded_imgs[image_idx] )\n",
    "    cv2.imwrite(\"./restructured/original-%s.jpg\" %name,x_valid[image_idx] )\n",
    "    plt.imshow(decoded_imgs[image_idx]/255)\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
